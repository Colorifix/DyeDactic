{"activation": "ReLU",
  "aggregation": "mean",
  "atom_messages": "",
  "batch_size": 70,
  "bias": "",
  "depth": 4,
  "dropout": 0.07928777915219476,
  "ffn_hidden_size": 100,
  "ffn_num_layers": 2,
  "final_lr": 0.0008745233959951397,
  "hidden_size": 300,
  "init_lr": 0.0010170618974826723,
  "max_lr": 0.008213119797581435,
  "warmup_epochs": 5,
  "id": "f8f937d8-e7f3-4073-a91c-e50fa78313d7"}